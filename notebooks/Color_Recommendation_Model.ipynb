{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQF9rC2rHtjq",
        "outputId": "37fa7576-eb17-4f47-c7cb-052a75ca309e"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UX35fWNxTTHg"
      },
      "source": [
        "### Transforming from JSON to CSV:\n",
        "Original dataset link: https://huggingface.co/datasets/huggingface-projects/color-palettes-sd/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkNT-K7cLVoQ"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "json_data = json.load(open('/content/drive/MyDrive/Colab Notebooks/ColorSchemes/dataset/text-to-image-dataset.json', 'r'))\n",
        "dataset = pd.DataFrame(columns={'prompt': pd.Series(dtype=str), 'imgURL': pd.Series(dtype=str), 'colors': pd.Series(dtype=object)})\n",
        "\n",
        "for obj in json_data:\n",
        "  prompt = obj['data']['prompt']\n",
        "  for img in obj['data']['images']:\n",
        "    colors = img['colors']\n",
        "    imgURL = img['imgURL']\n",
        "\n",
        "    dataset.loc[len(dataset.index)] = [prompt, imgURL, colors]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OlVrSE8FTdxx"
      },
      "outputs": [],
      "source": [
        "dataset.to_csv('/content/drive/MyDrive/Colab Notebooks/ColorSchemes/dataset/text-to-image-dataset-converted.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ji6cVvLfVkXt"
      },
      "source": [
        "### Using the new datatset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "q65d6M3AVNEl",
        "outputId": "6ca37b78-8eb1-412d-d18e-0070f87cc04c"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/ColorSchemes/dataset/text-to-image-dataset-converted.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EsvbAj8kHnhx"
      },
      "source": [
        "### Converting Hexcodes in RGB values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1_pWdNz1F_xo",
        "outputId": "a85f1569-98a9-4402-a2fe-ef1e04e0eafe"
      },
      "outputs": [],
      "source": [
        "def hex_to_rgb(hex_list_str: str):\n",
        "  rgb_list = []\n",
        "  hex_list = hex_list_str.strip('[]').split(', ')\n",
        "  for hex in hex_list:\n",
        "    hex = hex.strip('\"\\'')\n",
        "    rgb = []\n",
        "    for i in (1, 3, 5): # hexcodes must be strictly 6 characters + 1 ('#')\n",
        "      decimal = int(hex[i:i+2], 16)\n",
        "      rgb.append(decimal)\n",
        "\n",
        "    rgb_list.append(rgb)\n",
        "\n",
        "  return list(rgb_list)\n",
        "\n",
        "df['colors'] = df['colors'].apply(hex_to_rgb)\n",
        "df = df[['colors']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yx3jKjQM22BY"
      },
      "source": [
        "### Prepare the dataset and split into train, test, validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XKURcvao4LNU",
        "outputId": "e30b27b2-68db-4a10-bc95-8b2bb4e9f309"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "df.rename(columns={'colors': 'output'}, inplace=True)\n",
        "\n",
        "def random_filter(x: list):\n",
        "  rand_indices = torch.randint(low=0, high=len(x), size=(2,1), generator=torch.manual_seed(111))\n",
        "  rand_indices.sort()\n",
        "  out = [x[index] for index in rand_indices]\n",
        "  return out\n",
        "\n",
        "df['input'] = df['output'].apply(random_filter)\n",
        "df = df[['input', 'output']]\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPBTJhzB1IPk",
        "outputId": "386fb738-47ae-471a-b66b-62710580b496"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "9841\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# def split(full_dataset, val_percent, test_percent, random_seed=None):\n",
        "#   amount = len(full_dataset)\n",
        "\n",
        "#   test_amount = (\n",
        "#     int(amount * test_percent)\n",
        "#     if test_percent is not None else 0)\n",
        "#   val_amount = (\n",
        "#     int(amount * val_percent)\n",
        "#     if val_percent is not None else 0)\n",
        "#   train_amount = amount - test_amount - val_amount\n",
        "\n",
        "#   train_dataset, val_dataset, test_dataset = random_split(\n",
        "#     full_dataset,\n",
        "#     (train_amount, val_amount, test_amount),\n",
        "#     generator = (\n",
        "#       torch.Generator().manual_seed(random_seed)\n",
        "#       if random_seed\n",
        "#       else None\n",
        "#     )\n",
        "#   )\n",
        "#   return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "# train_data, val_data, test_data = split(df, 0.1, 0.2, 111)\n",
        "\n",
        "train_data = df['output']\n",
        "train_data_length = len(train_data)\n",
        "print(train_data_length)\n",
        "train_labels = torch.zeros(train_data_length)\n",
        "train_set = [(torch.tensor(train_data[i]), train_labels[i]) for i in range(train_data_length)]\n",
        "\n",
        "BATCH_SIZE = 32 # we will train the network in batches of data\n",
        "train_loader = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True, drop_last=True) # Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGMMCxdd3jNO"
      },
      "source": [
        "## Building GAN\n",
        "Input must be two colors. Output should be 3 more colors' values.\\\n",
        "Suggestions from [Sandhya Krishnan (Geek Culture)](https://medium.com/geekculture/introduction-to-neural-network-2f8b8221fbd3):\n",
        "- The number of hidden neurons should be between the size of the input layer and the size of the output layer.\n",
        "- The number of hidden neurons should be 2/3 the size of the input layer, plus the size of the output layer.\n",
        "- The number of hidden neurons should be less than twice the size of the input layer.\n",
        "\n",
        "size of input layer = 3 + 3 = 6\\\n",
        "size of output layer = 3 + 3 + 3 = 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AT76jNFYWY3N"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "\n",
        "class Generator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.sample_in = None\n",
        "    self.sample_out = None\n",
        "      # # V2:\n",
        "      # nn.Linear(6, 128),\n",
        "      # nn.LeakyReLU(),\n",
        "      # nn.Dropout(0.1),\n",
        "      # nn.Linear(128, 60),\n",
        "      # nn.LeakyReLU(),\n",
        "      # nn.Linear(60, 49),\n",
        "      # nn.LeakyReLU(),\n",
        "      # nn.Linear(49, 9),\n",
        "      # nn.Sigmoid() # to contain the output in a range\n",
        "\n",
        "      # # V3:\n",
        "      # nn.Linear(6, 128),\n",
        "      # nn.LeakyReLU(),\n",
        "      # nn.Linear(128, 94),\n",
        "      # nn.LeakyReLU(),\n",
        "      # nn.Linear(94, 72),\n",
        "      # nn.LeakyReLU(),\n",
        "      # nn.Linear(72, 56),\n",
        "      # nn.LeakyReLU(),\n",
        "      # nn.Linear(56, 9),\n",
        "      # nn.Sigmoid() # to contain the output in a range\n",
        "    self.model = nn.Sequential(\n",
        "      # V1 and V4:\n",
        "      nn.Linear(6, 18),\n",
        "      nn.LeakyReLU(),\n",
        "\n",
        "      nn.Linear(18, 27),\n",
        "      nn.LeakyReLU(),\n",
        "\n",
        "      nn.Linear(27, 9),\n",
        "      nn.Sigmoid() # to contain the output in a range\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    input = torch.reshape(x, shape=(x.size(dim=0), 6)) / 255 # change the range from [0-255] to [0-1]\n",
        "    output = self.model(input)\n",
        "    output = torch.reshape(output, shape=(x.size(dim=0), 3, 3)) * 255 # change the range from [0-1] to [0-255]\n",
        "    output = torch.cat((x, output), dim = 1)\n",
        "    return output\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.model = nn.Sequential(\n",
        "      nn.Linear(15, 256),\n",
        "      nn.LeakyReLU(),\n",
        "      nn.Dropout(0.3),\n",
        "\n",
        "      nn.Linear(256, 128),\n",
        "      nn.LeakyReLU(),\n",
        "      nn.Dropout(0.3),\n",
        "\n",
        "      nn.Linear(128, 64),\n",
        "      nn.LeakyReLU(),\n",
        "      nn.Dropout(0.3),\n",
        "\n",
        "      nn.Linear(64, 1),\n",
        "      nn.Sigmoid() # 0 means input was fake and 1 means input was real\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.reshape(x, shape=(x.size(dim=0), 15))\n",
        "    output = self.model(x)\n",
        "    output = torch.reshape(output, shape=(x.size(dim=0),1))\n",
        "    return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-XaLWvZ9JJ6"
      },
      "source": [
        "### Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pbgKtrmk8k3V",
        "outputId": "815e1483-928e-4a4e-850f-2aece45770e7"
      },
      "outputs": [],
      "source": [
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "LR = 0.001\n",
        "EPOCHS = 300\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "d_optim = torch.optim.Adam(discriminator.parameters(), lr=LR)\n",
        "g_optim = torch.optim.Adam(generator.parameters(), lr=LR)\n",
        "latent_space_samples = torch.rand(size=(BATCH_SIZE, 2, 3), generator=torch.manual_seed(111))*255 # fixed noise for generator\n",
        "\n",
        "REAL_DATA_LABEL = torch.ones((BATCH_SIZE, 1)) # 1 - real data\n",
        "GEN_DATA_LABEL = torch.zeros((BATCH_SIZE, 1)) # 0 - fake data\n",
        "DATA_LABELS = torch.cat((REAL_DATA_LABEL, GEN_DATA_LABEL))\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "  for n, (real_samples, _) in enumerate(train_loader):\n",
        "    generated_samples = generator(latent_space_samples)\n",
        "\n",
        "    # concatenate all the data into a single input and target (or labels) tensor\n",
        "    all_samples = torch.cat((real_samples, generated_samples))\n",
        "\n",
        "    # Training the discriminator\n",
        "    d_optim.zero_grad() # equivalent to discriminator.zero_gread()\n",
        "    output_discriminator = discriminator(all_samples)\n",
        "\n",
        "    loss_discriminator = loss_fn(output_discriminator, DATA_LABELS)\n",
        "    loss_discriminator.backward()\n",
        "    d_optim.step()\n",
        "\n",
        "    # Training the generator\n",
        "    g_optim.zero_grad() # equivalent to generator.zero_gread()\n",
        "    generated_samples = generator(latent_space_samples)\n",
        "    output_discriminator = discriminator(generated_samples)\n",
        "\n",
        "    # Generator loss\n",
        "    loss_generator = loss_fn(output_discriminator, REAL_DATA_LABEL) # Generator must produce realistic outputs\n",
        "    loss_generator.backward()\n",
        "    g_optim.step()\n",
        "\n",
        "    if (epoch % 10 == 0) and (n == BATCH_SIZE - 1):\n",
        "      loss_value = f\"Epoch: {epoch}. Discriminator Loss: {loss_discriminator}. Generator Loss: {loss_generator}\"\n",
        "      print(loss_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9SEvDykb6mG"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "ts = str(time.time())\n",
        "torch.save(generator.state_dict(), '/content/drive/MyDrive/Colab Notebooks/ColorSchemes/model/Generator.'+ts)\n",
        "torch.save(discriminator.state_dict(), '/content/drive/MyDrive/Colab Notebooks/ColorSchemes/model/Discriminator.'+ts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_22BFwGx_5GV"
      },
      "source": [
        "### Testing out the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOsG_gen27UE",
        "outputId": "07ad489e-b67c-4a06-f9a9-6b6cfa7c8c4a"
      },
      "outputs": [],
      "source": [
        "gen_model = Generator()\n",
        "gen_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/ColorSchemes/model/GeneratorV4'))\n",
        "gen_model.eval()\n",
        "\n",
        "def rgb_to_hex(r, g, b):\n",
        "  return '#{:02x}{:02x}{:02x}'.format(r, g, b)\n",
        "\n",
        "out = torch.round(gen_model(torch.tensor([\n",
        "    [[245., 173., 49.], [168., 9., 40.]],\n",
        "     [[58., 71., 36.], [41., 95., 105.]],\n",
        "     [[80., 65., 49.], [33., 25., 21.]],\n",
        "     [[178., 141., 74.], [204., 203., 160.]],\n",
        "     [[26., 46., 53.], [156., 176., 115.]],\n",
        "])).detach()).to(torch.int32)\n",
        "\n",
        "for res in out:\n",
        "  hex = []\n",
        "  for rgb in res:\n",
        "    hex.append(rgb_to_hex(*rgb))\n",
        "  print(*hex, sep='\\n')\n",
        "  print()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UX35fWNxTTHg",
        "Ji6cVvLfVkXt",
        "EsvbAj8kHnhx",
        "yx3jKjQM22BY",
        "jVq6YqCdaMem"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
